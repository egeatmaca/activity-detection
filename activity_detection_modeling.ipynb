{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCwLeR-EQrXz"
      },
      "source": [
        "## Import Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ra1zdSi8Qqk_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from lightgbm import LGBMClassifier\n",
        "import eli5\n",
        "import shap\n",
        "from glob import glob\n",
        "import time\n",
        "import gc\n",
        "import pickle\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.utils import ops as utils_ops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMkUmnj1GKoc"
      },
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7U8yD3_XsZE"
      },
      "source": [
        "### Feature Extraction Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAeNHsOvFs35"
      },
      "outputs": [],
      "source": [
        "# Get mediapipe pose model\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_pose = mp.solutions.pose\n",
        "\n",
        "# Get tf object detection model\n",
        "object_detection_model = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_640x640/1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHaoRDq7XDSt"
      },
      "outputs": [],
      "source": [
        "### Pose Estimation ###\n",
        "\n",
        "def estimate_pose(image):\n",
        "    # Setup mediapipe instance\n",
        "    pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
        "\n",
        "    # Recolor image to RGB\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image.flags.writeable = False\n",
        "\n",
        "    # Make detection\n",
        "    results = pose.process(image)\n",
        "\n",
        "    try:\n",
        "        return results.pose_landmarks.landmark\n",
        "    except AttributeError:\n",
        "        return None\n",
        "\n",
        "\n",
        "def calculate_angle(first, mid, end):\n",
        "    first = np.array(first) \n",
        "    mid = np.array(mid)  # Mid\n",
        "    end = np.array(end)  # End\n",
        "\n",
        "    radians = np.arctan2(end[1]-mid[1], end[0]-mid[0]) - \\\n",
        "        np.arctan2(first[1]-mid[1], first[0]-mid[0])\n",
        "    angle = np.abs(radians*180.0/np.pi)\n",
        "\n",
        "    if angle > 180.0:\n",
        "        angle = 360-angle\n",
        "\n",
        "    return angle\n",
        "\n",
        "def calculate_all_angles(landmarks):\n",
        "    angle_map = {\n",
        "        'SHOULDER': ['ELBOW', 'SHOULDER', 'HIP'],\n",
        "        'ELBOW': ['SHOULDER', 'ELBOW', 'WRIST'],\n",
        "        'HIP': ['KNEE', 'HIP', 'SHOULDER'],\n",
        "        'KNEE': ['HIP', 'KNEE', 'ANKLE'],\n",
        "        'ANKLE': ['KNEE', 'ANKLE', 'PINKY']\n",
        "    }\n",
        "    \n",
        "    angles = {}\n",
        "    for angle_name, landmark_points in angle_map.items():\n",
        "        for side in ['LEFT', 'RIGHT']:\n",
        "            # get landmark names\n",
        "            landmark_names = []\n",
        "            for point in landmark_points:\n",
        "                landmark_names.append(side+'_'+point)\n",
        "            # calculate angle\n",
        "            first = [landmarks[getattr(mp_pose.PoseLandmark, landmark_names[0]).value].x,\n",
        "                     landmarks[getattr(mp_pose.PoseLandmark, landmark_names[0]).value].y]\n",
        "            mid = [landmarks[getattr(mp_pose.PoseLandmark, landmark_names[1]).value].x,\n",
        "                   landmarks[getattr(mp_pose.PoseLandmark, landmark_names[1]).value].y]\n",
        "            end = [landmarks[getattr(mp_pose.PoseLandmark, landmark_names[2]).value].x,\n",
        "                   landmarks[getattr(mp_pose.PoseLandmark, landmark_names[2]).value].y]\n",
        "            visibility = np.mean([landmarks[getattr(mp_pose.PoseLandmark, landmark_names[0]).value].visibility,\n",
        "                          landmarks[getattr(mp_pose.PoseLandmark, landmark_names[1]).value].visibility,\n",
        "                          landmarks[getattr(mp_pose.PoseLandmark, landmark_names[2]).value].visibility])\n",
        "            angle = calculate_angle(first, mid, end)\n",
        "            angles[side+'_'+angle_name] = [angle]\n",
        "            angles[side+'_'+angle_name+'_visibility'] = [visibility]\n",
        "\n",
        "    angles = pd.DataFrame(angles)\n",
        "    return angles\n",
        "\n",
        "\n",
        "### Object Detection ###\n",
        "\n",
        "def resize_image(image, dsize=(640, 640)):\n",
        "    return cv2.resize(image, dsize=dsize, interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "def detect_objects(image, model=object_detection_model):\n",
        "  if image.shape != (640, 640):\n",
        "    # Format for the Tensor\n",
        "    image= resize_image(image)\n",
        "\n",
        "  # To Tensor\n",
        "  image_tensor  = tf.image.convert_image_dtype(image, tf.uint8)[tf.newaxis, ...]\n",
        "  # Make detections\n",
        "  detections = object_detection_model(image_tensor)\n",
        "  detections = {key: value.numpy() for key, value in detections.items()}\n",
        "  # Format results as dataframe\n",
        "  df_result = pd.DataFrame({\n",
        "    'class': detections['detection_classes'][0], \n",
        "    'detection_score': detections['detection_scores'][0], \n",
        "    'ymin': map(lambda x: x[0], detections['detection_boxes'][0]), \n",
        "    'xmin': map(lambda x: x[1], detections['detection_boxes'][0]), \n",
        "    'ymax': map(lambda x: x[2], detections['detection_boxes'][0]), \n",
        "    'xmax': map(lambda x: x[3], detections['detection_boxes'][0]),\n",
        "  })\n",
        "  # Filter necessary objects\n",
        "  objects = {'laptop': df_result[df_result['class']==73],\n",
        "              'keyboard': df_result[df_result['class']==76],\n",
        "              'cellphone': df_result[df_result['class']==77],}\n",
        "\n",
        "  return objects\n",
        "\n",
        "### Feature Extraction ###\n",
        "\n",
        "def sightline_intersects(ear, nose, obj_xmin, obj_ymin, obj_xmax, obj_ymax, img_shape):\n",
        "  sightline = (nose[0]-ear[0],nose[1]-ear[1])\n",
        "  current_point = (nose[0],nose[1])\n",
        "  intersects = False\n",
        "  while current_point[0] < img_shape[0] and current_point[1] < img_shape[1] \\\n",
        "      and current_point[0] > 0 and current_point[0] > 0 and not intersects:\n",
        "      if current_point[0] < obj_xmax and current_point[1] < obj_ymax \\\n",
        "          and current_point[0] > obj_xmin and current_point[0] > obj_ymin:\n",
        "          intersects = True\n",
        "      else:\n",
        "          current_point = (current_point[0] + sightline[0], current_point[1] + sightline[1])\n",
        "  return intersects\n",
        "\n",
        "def looks_at(image):\n",
        "  looks_at_ = {'laptop': 0, 'keyboard': 0, 'cellphone': 0}\n",
        "  # resize\n",
        "  image = resize_image(image)\n",
        "  # estimate pose landmarks\n",
        "  landmarks = estimate_pose(image)\n",
        "  if landmarks:\n",
        "    # detect objects\n",
        "    objects = detect_objects(image)\n",
        "    # find objects user is looking at\n",
        "    nose = landmarks[getattr(mp_pose.PoseLandmark, 'NOSE').value]\n",
        "    sides = ['LEFT_', 'RIGHT_']\n",
        "    for side in sides:\n",
        "      ear = landmarks[getattr(mp_pose.PoseLandmark, side+'EAR').value]\n",
        "      for obj, df in objects.items():\n",
        "        for i in df.index:\n",
        "          obj_row = df.loc[i]\n",
        "          looks_at_[obj] = int((looks_at_[obj]==True) | sightline_intersects(\n",
        "              [ear.x, ear.y], [nose.x, nose.y], obj_row.xmin, obj_row.ymin, obj_row.xmax, obj_row.ymax, image.shape))\n",
        "  return pd.DataFrame({key: [value] for key, value in looks_at_.items()})\n",
        "\n",
        "\n",
        "def hand_at(image):\n",
        "  hand_at_ = {'laptop': 0, 'keyboard': 0, 'cellphone': 0}\n",
        "  # resize\n",
        "  image = resize_image(image)\n",
        "  # estimate pose landmarks\n",
        "  landmarks = estimate_pose(image)\n",
        "  if landmarks:\n",
        "    # detect objects\n",
        "    objects = detect_objects(image)\n",
        "    # find objects at hand\n",
        "    fingers = ['LEFT_PINKY', 'RIGHT_PINKY', 'LEFT_INDEX', 'RIGHT_INDEX']\n",
        "    for finger in fingers:\n",
        "      finger = landmarks[getattr(mp_pose.PoseLandmark, finger).value]\n",
        "      for obj, df in objects.items():\n",
        "        for i in df.index:\n",
        "          obj_row = df.loc[i]\n",
        "          hand_at_[obj] = int((hand_at_[obj]==True) | (obj_row.xmin < finger.x and finger.x < obj_row.xmax and \n",
        "                                                       obj_row.ymin < finger.y and finger.y < obj_row.ymax))\n",
        "  return pd.DataFrame({key: [value] for key, value in hand_at_.items()})\n",
        "\n",
        "def focus_objects(image):\n",
        "  looks_at_ = {'laptop': 0, 'keyboard': 0, 'cellphone': 0}\n",
        "  hand_at_ = {'laptop': 0, 'keyboard': 0, 'cellphone': 0}\n",
        "  # resize\n",
        "  image = resize_image(image)\n",
        "  # estimate pose landmarks\n",
        "  landmarks = estimate_pose(image)\n",
        "  if landmarks:\n",
        "    # detect objects\n",
        "    objects = detect_objects(image)\n",
        "    # iterate over objects\n",
        "    for obj, df in objects.items():\n",
        "      for i in df.index:\n",
        "        obj_row = df.loc[i]\n",
        "        \n",
        "        # find objects at hand\n",
        "        fingers = ['LEFT_PINKY', 'RIGHT_PINKY', 'LEFT_INDEX', 'RIGHT_INDEX']\n",
        "        for finger in fingers:\n",
        "          finger = landmarks[getattr(mp_pose.PoseLandmark, finger).value]\n",
        "          hand_at_[obj] = int((hand_at_[obj]==True) | (obj_row.xmin < finger.x and finger.x < obj_row.xmax and \n",
        "                                                      obj_row.ymin < finger.y and finger.y < obj_row.ymax))\n",
        "        \n",
        "        # find objects user is looking at\n",
        "        nose = landmarks[getattr(mp_pose.PoseLandmark, 'NOSE').value]\n",
        "        sides = ['LEFT_', 'RIGHT_']\n",
        "        for side in sides:\n",
        "          ear = landmarks[getattr(mp_pose.PoseLandmark, side+'EAR').value]\n",
        "          looks_at_[obj] = int((looks_at_[obj]==True) | sightline_intersects(\n",
        "              [ear.x, ear.y], [nose.x, nose.y], obj_row.xmin, obj_row.ymin, obj_row.xmax, obj_row.ymax, image.shape))\n",
        "          \n",
        "  return pd.concat([pd.DataFrame({'hand_at_'+key: [value] for key, value in hand_at_.items()}),\n",
        "                    pd.DataFrame({'looks_at_'+key: [value] for key, value in looks_at_.items()})], axis=1)\n",
        "\n",
        "def extract_features(image):\n",
        "  angles = None\n",
        "  focus_objects_ = None\n",
        "  # estimate pose landmarks\n",
        "  landmarks = estimate_pose(image)\n",
        "  if landmarks:\n",
        "    # calculate all angles\n",
        "    angles = calculate_all_angles(landmarks)\n",
        "    # find what is at the hand and what is at the sightline\n",
        "    focus_objects_ = focus_objects(image)\n",
        "    # concat features\n",
        "    features = pd.concat([angles, focus_objects_], axis=1)\n",
        "    return features\n",
        "  else:\n",
        "    return None\n",
        "\n",
        "def process_folder(folder_path, name, label, start_iter=0):\n",
        "    # for each image in the folder\n",
        "    img_paths = glob(folder_path+'/*.JPG') + glob(folder_path+'/*.jpg') + glob(folder_path+'/*.png') + glob(folder_path+'/*.PNG')\n",
        "    n_process = 10\n",
        "    n = len(img_paths)\n",
        "    steps = int(n / n_process)\n",
        "    for i in range(start_iter, steps):\n",
        "        data = pd.DataFrame()\n",
        "        iter_paths = img_paths[i*n_process:(i+1)*n_process]\n",
        "        for j, img_path in enumerate(iter_paths):\n",
        "            print(i*n_process+j, img_path)\n",
        "            # read image\n",
        "            image = cv2.imread(img_path)\n",
        "            # extract features\n",
        "            features = extract_features(image)\n",
        "            del image\n",
        "            gc.collect()\n",
        "            data = pd.concat([data, features])\n",
        "        data['label'] = label\n",
        "        data.to_excel(os.path.join('feature-extraction', name+str(i)+'.xlsx'), index=False)\n",
        "        del data\n",
        "        gc.collect()\n",
        "        print(f'Iter {i} completed!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YQ2QP9jXzF8"
      },
      "source": [
        "### Feature Extraction Job for Activity Detection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQxOQFcSXA9N"
      },
      "outputs": [],
      "source": [
        "process_folder('activity-detection-data/object-detection-assets/non-working-no-angle', 'not-working', 0, start_iter=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44OQBedzYAVT",
        "outputId": "9f32d39a-6e8e-4dc7-c65b-d2bd2ab1baac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "110 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142533.jpg\n",
            "111 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142526.jpg\n",
            "112 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142515.jpg\n",
            "113 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142528.jpg\n",
            "114 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142518.jpg\n",
            "115 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142513.jpg\n",
            "116 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142511 (1).jpg\n",
            "117 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142509.jpg\n",
            "118 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142511.jpg\n",
            "119 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142510.jpg\n",
            "Iter 11 completed!\n",
            "120 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142500.jpg\n",
            "121 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142503 (1).jpg\n",
            "122 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142503.jpg\n",
            "123 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142459.jpg\n",
            "124 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142624 (1).jpg\n",
            "125 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142625 (1).jpg\n",
            "126 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142629.jpg\n",
            "127 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142624.jpg\n",
            "128 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142623 (1).jpg\n",
            "129 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142623.jpg\n",
            "Iter 12 completed!\n",
            "130 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142625.jpg\n",
            "131 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142618 (1).jpg\n",
            "132 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142622.jpg\n",
            "133 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142618.jpg\n",
            "134 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142617.jpg\n",
            "135 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142616.jpg\n",
            "136 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142615.jpg\n",
            "137 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142612.jpg\n",
            "138 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142610.jpg\n",
            "139 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142604.jpg\n",
            "Iter 13 completed!\n",
            "140 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142611.jpg\n",
            "141 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142601.jpg\n",
            "142 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142606.jpg\n",
            "143 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142607.jpg\n",
            "144 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142603.jpg\n",
            "145 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142605.jpg\n",
            "146 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142600.jpg\n",
            "147 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142559.jpg\n",
            "148 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142557.jpg\n",
            "149 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142556.jpg\n",
            "Iter 14 completed!\n",
            "150 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142558.jpg\n",
            "151 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142553.jpg\n",
            "152 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142554.jpg\n",
            "153 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142548.jpg\n",
            "154 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142702.jpg\n",
            "155 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142659.jpg\n",
            "156 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142654.jpg\n",
            "157 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142644.jpg\n",
            "158 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142643.jpg\n",
            "159 activity-detection-data/object-detection-assets/working-no-angle/VideoCapture_20220702-142631.jpg\n",
            "Iter 15 completed!\n"
          ]
        }
      ],
      "source": [
        "process_folder('activity-detection-data/object-detection-assets/working-no-angle', 'working', 1, start_iter=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjeJ8swf7v04"
      },
      "outputs": [],
      "source": [
        "# concatanate all data\n",
        "df = pd.DataFrame()\n",
        "for p in glob('feature-extraction/*.xlsx'):\n",
        "  df = pd.concat([df, pd.read_excel(p).reset_index(drop=True)])\n",
        "df.to_excel('./data/working-detection.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaD5EWLII8eV"
      },
      "source": [
        "## Data Preperation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G28vT9sZIr3M"
      },
      "outputs": [],
      "source": [
        "df_model = pd.read_excel('./data/working-detection-final.xlsx', engine='openpyxl')\n",
        "X = df_model.drop(columns='label')\n",
        "y = df_model['label']\n",
        "\n",
        "# train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# balance sides in the training set (mirror images)\n",
        "X_mirrored = X_train.copy()\n",
        "mirrored_cols = ['RIGHT_SHOULDER', 'LEFT_SHOULDER', 'RIGHT_ELBOW', 'LEFT_ELBOW', \n",
        "       'RIGHT_HIP', 'LEFT_HIP', 'RIGHT_KNEE', 'LEFT_KNEE', 'RIGHT_ANKLE', 'LEFT_ANKLE'] \n",
        "mirrored_cols = [[c, c+'_visibility'] for c in mirrored_cols]\n",
        "mirrored_cols = [item for sublist in mirrored_cols for item in sublist] \n",
        "mirrored_cols = mirrored_cols + ['looks_at_laptop', 'looks_at_keyboard', 'looks_at_cellphone', 'hand_at_laptop', 'hand_at_keyboard', 'hand_at_cellphone']\n",
        "X_mirrored = X_mirrored[mirrored_cols]\n",
        "X_mirrored.columns = X_train.columns\n",
        "X_train = pd.concat([X_train, X_mirrored])\n",
        "y_train = pd.concat([y_train, y_train])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdLNCr93dXBt"
      },
      "source": [
        "## Try the first model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ms69p-5udut6"
      },
      "outputs": [],
      "source": [
        "model = LGBMClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1KM0ynD57km",
        "outputId": "288b2e05-9d1e-4eee-a908-c6ca918a7143"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Results:\n",
            "                   0          1  accuracy  macro avg  weighted avg\n",
            "precision   0.966667   0.882353  0.921875   0.924510      0.925827\n",
            "recall      0.878788   0.967742  0.921875   0.923265      0.921875\n",
            "f1-score    0.920635   0.923077  0.921875   0.921856      0.921818\n",
            "support    33.000000  31.000000  0.921875  64.000000     64.000000\n"
          ]
        }
      ],
      "source": [
        "print('First Results:', pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)), sep='\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp-8g5MH6aWJ"
      },
      "source": [
        "## Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "mPzZb-orUizQ",
        "outputId": "24ef740f-9a75-4972-dfd8-57982be39f9c"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline(steps=[(\"scaler\", MinMaxScaler()), (\"classifier\", LGBMClassifier())])\n",
        "\n",
        "params = [\n",
        "    {\n",
        "      'scaler': [StandardScaler(), MinMaxScaler()],\n",
        "      'classifier': [LogisticRegression()],\n",
        "      \"classifier__C\": [0.1, 1.0, 10.0, 100.0],\n",
        "    },\n",
        "    {\n",
        "      'scaler': [StandardScaler(), MinMaxScaler()],\n",
        "      'classifier': [RandomForestClassifier()],\n",
        "      'classifier__max_depth': np.arange(1, 22, 2),\n",
        "      'classifier__n_estimators': np.arange(10, 500, 50),\n",
        "    },\n",
        "    {\n",
        "      'scaler': [StandardScaler(), MinMaxScaler()],\n",
        "      'classifier': [LGBMClassifier()],\n",
        "      'classifier__max_depth': np.arange(1, 52, 2),\n",
        "      'classifier__num_leaves': np.arange(2, 203, 5),\n",
        "      'classifier__n_estimators': np.arange(10, 501, 50),\n",
        "      'classifier__learning_rate': np.arange(0.01, 1.502, 0.05)\n",
        "    },\n",
        "]\n",
        "\n",
        "print('Tuning the model...')\n",
        "search = RandomizedSearchCV(pipeline, params, n_iter=500, cv=10, random_state=42)\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "print('Best Estimator:', search.best_estimator_)\n",
        "print('Best Score:', search.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHYIBl_cASiE"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKO7tJzeAOG7"
      },
      "outputs": [],
      "source": [
        "model = Pipeline(steps=[('scaler', StandardScaler()),\n",
        "                ('classifier',\n",
        "                 LGBMClassifier(learning_rate=0.5, max_depth=11,\n",
        "                                n_estimators=310, num_leaves=137))])\n",
        "\n",
        "# uncomment to load the pretrained model\n",
        "# model = pickle.load(open('activity_detection_model3.pkl', 'rb'))\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXMFwTMZAo3Y",
        "outputId": "b383eb96-57c1-49fb-8098-561f659e3cec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results of the Tuned Model:\n",
            "                   0          1  accuracy  macro avg  weighted avg\n",
            "precision   0.968750   0.937500  0.953125   0.953125      0.953613\n",
            "recall      0.939394   0.967742  0.953125   0.953568      0.953125\n",
            "f1-score    0.953846   0.952381  0.953125   0.953114      0.953136\n",
            "support    33.000000  31.000000  0.953125  64.000000     64.000000\n"
          ]
        }
      ],
      "source": [
        "print('Results of the Tuned Model:', pd.DataFrame(classification_report(y_test, y_pred>0.5, output_dict=True)), sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLkmaCTjL-f2"
      },
      "outputs": [],
      "source": [
        "# save the model\n",
        "model_path = 'activity_detection_pose+focusobjects.pkl'\n",
        "model_file = open(model_path, 'wb')\n",
        "pickle.dump(model, model_file)\n",
        "model_file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a2Ft6ujDFIs"
      },
      "source": [
        "## Model Explanation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-5Yv0_mDPK2",
        "outputId": "d28fc765-c815-4678-e2e6-d5c3d064474a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results of the Tuned Model:\n",
            "                      feature    weight\n",
            "0                    LEFT_HIP  0.143008\n",
            "1                 RIGHT_ELBOW  0.142078\n",
            "2                  LEFT_ELBOW  0.115813\n",
            "3                 RIGHT_ANKLE  0.100944\n",
            "4                   LEFT_KNEE  0.072353\n",
            "5                  LEFT_ANKLE  0.063394\n",
            "6                  RIGHT_KNEE  0.061872\n",
            "7                   RIGHT_HIP  0.059017\n",
            "8              RIGHT_SHOULDER  0.050530\n",
            "9               LEFT_SHOULDER  0.045624\n",
            "10     RIGHT_ELBOW_visibility  0.022775\n",
            "11      LEFT_ELBOW_visibility  0.021025\n",
            "12             hand_at_laptop  0.017657\n",
            "13      RIGHT_KNEE_visibility  0.010580\n",
            "14  RIGHT_SHOULDER_visibility  0.010206\n",
            "15      LEFT_ANKLE_visibility  0.010016\n",
            "16            looks_at_laptop  0.009483\n",
            "17       LEFT_KNEE_visibility  0.009276\n",
            "18   LEFT_SHOULDER_visibility  0.008465\n",
            "19       RIGHT_HIP_visibility  0.007240\n",
            "20          hand_at_cellphone  0.005272\n",
            "21         looks_at_cellphone  0.004416\n",
            "22        LEFT_HIP_visibility  0.003679\n",
            "23     RIGHT_ANKLE_visibility  0.002741\n",
            "24           hand_at_keyboard  0.001932\n",
            "25          looks_at_keyboard  0.000602\n"
          ]
        }
      ],
      "source": [
        "feature_weights = eli5.explain_weights_df(model, feature_names=X_train.columns)\n",
        "print('Results of the Tuned Model:', feature_weights, sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARFODdcetiHR",
        "outputId": "9196e83e-583c-4c35-85b1-4ed52b1f9d1e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Permutation explainer: 65it [00:27,  1.73it/s]\n"
          ]
        }
      ],
      "source": [
        "# Fits the explainer\n",
        "explainer = shap.Explainer(model.predict, X_test)\n",
        "# Calculates the SHAP values - It takes some time\n",
        "shap_values = explainer(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "Tu6Y-LWTwt8P",
        "outputId": "27e7f618-62df-4de7-dee8-18e694e33c5d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b45aa14c-a50f-44ca-aa7d-30e0136f6af4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LEFT_SHOULDER</th>\n",
              "      <td>-0.020518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LEFT_SHOULDER_visibility</th>\n",
              "      <td>-0.003840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RIGHT_SHOULDER</th>\n",
              "      <td>-0.010838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RIGHT_SHOULDER_visibility</th>\n",
              "      <td>-0.002894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LEFT_ELBOW</th>\n",
              "      <td>-0.030040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LEFT_ELBOW_visibility</th>\n",
              "      <td>-0.011416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RIGHT_ELBOW</th>\n",
              "      <td>-0.033775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RIGHT_ELBOW_visibility</th>\n",
              "      <td>-0.007760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LEFT_HIP</th>\n",
              "      <td>-0.049295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LEFT_HIP_visibility</th>\n",
              "      <td>-0.003025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RIGHT_HIP</th>\n",
              "      <td>-0.027199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RIGHT_HIP_visibility</th>\n",
              "      <td>0.002683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LEFT_KNEE</th>\n",
              "      <td>-0.027252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LEFT_KNEE_visibility</th>\n",
              "      <td>-0.006287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RIGHT_KNEE</th>\n",
              "      <td>-0.056739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RIGHT_KNEE_visibility</th>\n",
              "      <td>-0.000132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LEFT_ANKLE</th>\n",
              "      <td>-0.030329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LEFT_ANKLE_visibility</th>\n",
              "      <td>-0.004498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RIGHT_ANKLE</th>\n",
              "      <td>-0.077020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RIGHT_ANKLE_visibility</th>\n",
              "      <td>-0.004314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hand_at_laptop</th>\n",
              "      <td>-0.015572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hand_at_keyboard</th>\n",
              "      <td>-0.000368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hand_at_cellphone</th>\n",
              "      <td>-0.006550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>looks_at_laptop</th>\n",
              "      <td>-0.009549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>looks_at_keyboard</th>\n",
              "      <td>0.000079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>looks_at_cellphone</th>\n",
              "      <td>-0.002946</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b45aa14c-a50f-44ca-aa7d-30e0136f6af4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b45aa14c-a50f-44ca-aa7d-30e0136f6af4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b45aa14c-a50f-44ca-aa7d-30e0136f6af4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                  0\n",
              "LEFT_SHOULDER             -0.020518\n",
              "LEFT_SHOULDER_visibility  -0.003840\n",
              "RIGHT_SHOULDER            -0.010838\n",
              "RIGHT_SHOULDER_visibility -0.002894\n",
              "LEFT_ELBOW                -0.030040\n",
              "LEFT_ELBOW_visibility     -0.011416\n",
              "RIGHT_ELBOW               -0.033775\n",
              "RIGHT_ELBOW_visibility    -0.007760\n",
              "LEFT_HIP                  -0.049295\n",
              "LEFT_HIP_visibility       -0.003025\n",
              "RIGHT_HIP                 -0.027199\n",
              "RIGHT_HIP_visibility       0.002683\n",
              "LEFT_KNEE                 -0.027252\n",
              "LEFT_KNEE_visibility      -0.006287\n",
              "RIGHT_KNEE                -0.056739\n",
              "RIGHT_KNEE_visibility     -0.000132\n",
              "LEFT_ANKLE                -0.030329\n",
              "LEFT_ANKLE_visibility     -0.004498\n",
              "RIGHT_ANKLE               -0.077020\n",
              "RIGHT_ANKLE_visibility    -0.004314\n",
              "hand_at_laptop            -0.015572\n",
              "hand_at_keyboard          -0.000368\n",
              "hand_at_cellphone         -0.006550\n",
              "looks_at_laptop           -0.009549\n",
              "looks_at_keyboard          0.000079\n",
              "looks_at_cellphone        -0.002946"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(shap_values.values[y_test==0].mean(axis=0).reshape((1, 26)), columns = X_train.columns).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "o07NguDNx9PH",
        "outputId": "fd8d6e4a-9428-44e6-e41a-e5cc90c31799"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e7ed0759-ece7-4385-92af-cd3f12d6ce67\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LEFT_SHOULDER</th>\n",
              "      <td>0.020329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LEFT_SHOULDER_visibility</th>\n",
              "      <td>0.004508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RIGHT_SHOULDER</th>\n",
              "      <td>0.009381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RIGHT_SHOULDER_visibility</th>\n",
              "      <td>0.002632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LEFT_ELBOW</th>\n",
              "      <td>0.037186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LEFT_ELBOW_visibility</th>\n",
              "      <td>0.009605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RIGHT_ELBOW</th>\n",
              "      <td>0.035114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RIGHT_ELBOW_visibility</th>\n",
              "      <td>0.006048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LEFT_HIP</th>\n",
              "      <td>0.053735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LEFT_HIP_visibility</th>\n",
              "      <td>0.002996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RIGHT_HIP</th>\n",
              "      <td>0.033126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RIGHT_HIP_visibility</th>\n",
              "      <td>-0.002436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LEFT_KNEE</th>\n",
              "      <td>0.028646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LEFT_KNEE_visibility</th>\n",
              "      <td>0.006328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RIGHT_KNEE</th>\n",
              "      <td>0.060652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RIGHT_KNEE_visibility</th>\n",
              "      <td>0.000896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LEFT_ANKLE</th>\n",
              "      <td>0.033462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LEFT_ANKLE_visibility</th>\n",
              "      <td>0.004256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RIGHT_ANKLE</th>\n",
              "      <td>0.080533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RIGHT_ANKLE_visibility</th>\n",
              "      <td>0.005628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hand_at_laptop</th>\n",
              "      <td>0.013693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hand_at_keyboard</th>\n",
              "      <td>0.000560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hand_at_cellphone</th>\n",
              "      <td>0.007813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>looks_at_laptop</th>\n",
              "      <td>0.008317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>looks_at_keyboard</th>\n",
              "      <td>0.000392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>looks_at_cellphone</th>\n",
              "      <td>0.004340</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7ed0759-ece7-4385-92af-cd3f12d6ce67')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7ed0759-ece7-4385-92af-cd3f12d6ce67 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7ed0759-ece7-4385-92af-cd3f12d6ce67');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                  0\n",
              "LEFT_SHOULDER              0.020329\n",
              "LEFT_SHOULDER_visibility   0.004508\n",
              "RIGHT_SHOULDER             0.009381\n",
              "RIGHT_SHOULDER_visibility  0.002632\n",
              "LEFT_ELBOW                 0.037186\n",
              "LEFT_ELBOW_visibility      0.009605\n",
              "RIGHT_ELBOW                0.035114\n",
              "RIGHT_ELBOW_visibility     0.006048\n",
              "LEFT_HIP                   0.053735\n",
              "LEFT_HIP_visibility        0.002996\n",
              "RIGHT_HIP                  0.033126\n",
              "RIGHT_HIP_visibility      -0.002436\n",
              "LEFT_KNEE                  0.028646\n",
              "LEFT_KNEE_visibility       0.006328\n",
              "RIGHT_KNEE                 0.060652\n",
              "RIGHT_KNEE_visibility      0.000896\n",
              "LEFT_ANKLE                 0.033462\n",
              "LEFT_ANKLE_visibility      0.004256\n",
              "RIGHT_ANKLE                0.080533\n",
              "RIGHT_ANKLE_visibility     0.005628\n",
              "hand_at_laptop             0.013693\n",
              "hand_at_keyboard           0.000560\n",
              "hand_at_cellphone          0.007813\n",
              "looks_at_laptop            0.008317\n",
              "looks_at_keyboard          0.000392\n",
              "looks_at_cellphone         0.004340"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(shap_values.values[y_test==1].mean(axis=0).reshape((1, 26)), columns = X_train.columns).T"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "1Tsjw1wsXFDo",
        "lmAvCfLOg9sX",
        "HCwLeR-EQrXz",
        "L7U8yD3_XsZE"
      ],
      "name": "activity_detection_final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
